{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils.dbobjects import *\n",
    "from utils.utils import *\n",
    "from urllib.request import urlretrieve\n",
    "from scripts.config import read_api_key\n",
    "from comsear import ComicVineClient\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.exc import IntegrityError\n",
    "import pprint\n",
    "import functools\n",
    "import json\n",
    "import shutil\n",
    "import pprint as pp\n",
    "import re\n",
    "import os\n",
    "\n",
    "import filecmp\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "api_key = read_api_key()\n",
    "cv = ComicVineClient(api_key)\n",
    "\n",
    "class LibraryParser:\n",
    "    def __init__(self, library_path):\n",
    "        self.library_path = Path(library_path).resolve()\n",
    "        self.n_comics = None\n",
    "        self.n_volumes = None\n",
    "        self.folder_paths = []\n",
    "        self.library_dict = {}\n",
    "        \n",
    "    def library_watchdog(self):\n",
    "        pass\n",
    "    \n",
    "    def scan_root_folder(self):\n",
    "        #folders = list({each.parent for each_ext in ['*.cbr', '*.cbz'] for each in self.library_path.rglob(each_ext)})\n",
    "        folddict = {}\n",
    "        for each_ext in ['*.cbr', '*.cbz']:\n",
    "            for each in self.library_path.rglob(each_ext):\n",
    "                if each.parent.resolve() in folddict:\n",
    "                    folddict[each.parent.resolve()].append(each.resolve())\n",
    "                else:\n",
    "                    folddict[each.parent.resolve()] = [each.resolve()]\n",
    "        \n",
    "        collection_types = ['Issues', 'TPB']\n",
    "\n",
    "        for each in folddict:\n",
    "            if any(collection in each.name for collection in collection_types):\n",
    "                for collection in collection_types:\n",
    "                    if collection in each.name:\n",
    "                        if each.parent.name not in self.library_dict:\n",
    "                            self.library_dict[each.parent.name] = {collection.lower() : {'path' : [each], 'assets_in_folder' : folddict[each]}}\n",
    "                            \n",
    "                        else:\n",
    "                            if collection.lower() not in self.library_dict[each.parent.name]:\n",
    "                                self.library_dict[each.parent.name].update({collection.lower() : {'path' : [each], 'assets_in_folder' : folddict[each]}})\n",
    "                            else:\n",
    "                                #Check here for diffs (Next version update)\n",
    "                                self.library_dict[each.parent.name][collection.lower()]['path'].append(each)\n",
    "            else:\n",
    "                self.library_dict[each.name] = {'issues' : {'path' : each, 'assets_in_folder' : folddict[each]}}\n",
    "        \n",
    "    def volumify(self):\n",
    "        for each in self.library_dict:            \n",
    "             for each_type in self.library_dict[each]:\n",
    "                self.library_dict[each][each_type]['parser'] = VolumeParser(name=each, path=self.library_dict[each][each_type]['path'], comics_in_folder=self.library_dict[each][each_type]['assets_in_folder'])\n",
    "    def parse_library(self):\n",
    "        [self.library_dict[each_volume][each_type]['parser'].parseVolume() for each_volume in self.library_dict.keys() for each_type in self.library_dict[each_volume].keys()]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Age of Ultron': {'issues': {'parser': <__main__.VolumeParser object at 0x11864ceb8>,\n",
      "                              'path': [PosixPath('/Users/srihari/Fun/Comics/data/Age of Ultron/Issues')]}},\n",
      " 'Incredible Hulk 600-611 (2009-2010)': {'issues': {'parser': <__main__.VolumeParser object at 0x11864c978>,\n",
      "                                                    'path': [PosixPath('/Users/srihari/Fun/Comics/data/Hulk/Incredible Hulk 600-611 (2009-2010)/Issues')]}},\n",
      " 'Infinity Gauntlet': {'issues': {'parser': <__main__.VolumeParser object at 0x11864cb70>,\n",
      "                                  'path': [PosixPath('/Users/srihari/Fun/Comics/data/Infinity Gauntlet/Issues')]},\n",
      "                       'tpb': {'parser': <__main__.VolumeParser object at 0x11864cb38>,\n",
      "                               'path': [PosixPath('/Users/srihari/Fun/Comics/data/Infinity Gauntlet/TPB')]}},\n",
      " 'Infinity Gauntlet Aftermath': {'tpb': {'parser': <__main__.VolumeParser object at 0x11864cba8>,\n",
      "                                         'path': [PosixPath('/Users/srihari/Fun/Comics/data/Infinity Gauntlet/Infinity Gauntlet Aftermath/TPB')]}},\n",
      " 'Inhumans (01-12) (1998-1999)': {'issues': {'parser': <__main__.VolumeParser object at 0x11864ce80>,\n",
      "                                             'path': PosixPath('/Users/srihari/Fun/Comics/data/Inhumans/Inhumans (01-12) (1998-1999)')}},\n",
      " 'Marvel Graphic Novel  (01 - 05)': {'issues': {'parser': <__main__.VolumeParser object at 0x11864ca20>,\n",
      "                                                'path': PosixPath('/Users/srihari/Fun/Comics/data/Marvel Graphic Novel  (01 - 05)')}},\n",
      " 'Thor Vol. 2 (1998-2004)': {'issues': {'parser': <__main__.VolumeParser object at 0x11864ca90>,\n",
      "                                        'path': [PosixPath('/Users/srihari/Fun/Comics/data/Thor/Thor Vol. 2 (1998-2004)/Issues')]}},\n",
      " 'Venom (Vol. 2)': {'issues': {'parser': <__main__.VolumeParser object at 0x11864ca58>,\n",
      "                               'path': PosixPath('/Users/srihari/Fun/Comics/data/Venom (Vol. 2)')}}}\n"
     ]
    }
   ],
   "source": [
    "x = LibraryParser('../data/')\n",
    "x.scan_root_folder()\n",
    "x.volumify()\n",
    "pp.pprint(x.library_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 058 [560] (2003) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 067 [569] (2003) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 041 [543] (2001) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 060 [562] (2003) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 049 [551] (2002) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 037 [539] (2001) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 079 [581] (2004) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 073 [575] (2004) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 074 [576] (2004) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 046 [548] (2002) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 068 [570] (2003) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 039 [541] (2001) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 082 [584] (2004) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 070 [572] (2003) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 085 [587] (2004) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 069 [571] (2003) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 038 [540] (2001) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 075 [577] (2004) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 072 [574] (2004) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 078 [580] (2004) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 084 [586] (2004) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 083 [585] (2004) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 061 [563] (2003) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 048 [550] (2002) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 066 [568] (2003) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 059 [561] (2003) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 036 [538] (2001) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 031 (2001) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 050 [552] (2002) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 080 [582] (2004) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 071 [573] (2004) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 044 [546] (2002) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 076 [578] (2004) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 043 [545] (2002) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 056 [558] (2003) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 053 [555] (2002) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 054 [556] (2002) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 065 [567] (2003) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 062 [564] (2003) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 055 [557] (2002) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 035 (2001) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 052 [554] (2002) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 063 [565] (2003) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 042 [544] (2001) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 064 [566] (2003) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 034 (2001) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 030 (2000) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 081 [583] (2004) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 032 (2001) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 057 [559] (2003) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 033 (2001) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 077 [579] (2004) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Thor/Thor Vol. 2 (1998-2004)/Issues/Thor 045 [547] (2002) (Digital) (AnPymGold - Empire).cbr'), PosixPath('../data/Hulk/Incredible Hulk 600-611 (2009-2010)/Issues/Incredible Hulk 606 (2010).cbr'), PosixPath('../data/Hulk/Incredible Hulk 600-611 (2009-2010)/Issues/Incredible Hulk 600 (2009).cbr'), PosixPath('../data/Hulk/Incredible Hulk 600-611 (2009-2010)/Issues/Incredible Hulk 604 (2010).cbr'), PosixPath('../data/Hulk/Incredible Hulk 600-611 (2009-2010)/Issues/Incredible Hulk 609 (2010).cbr'), PosixPath('../data/Hulk/Incredible Hulk 600-611 (2009-2010)/Issues/Incredible Hulk 610 (2010).cbr'), PosixPath('../data/Hulk/Incredible Hulk 600-611 (2009-2010)/Issues/Incredible Hulk 602 (2009).cbr'), PosixPath('../data/Hulk/Incredible Hulk 600-611 (2009-2010)/Issues/Incredible Hulk 601 (2009).cbr'), PosixPath('../data/Hulk/Incredible Hulk 600-611 (2009-2010)/Issues/Incredible Hulk 607 (2010).cbr'), PosixPath('../data/Hulk/Incredible Hulk 600-611 (2009-2010)/Issues/Incredible Hulk 611 (2010).cbr'), PosixPath('../data/Hulk/Incredible Hulk 600-611 (2009-2010)/Issues/Incredible Hulk 603 (2009).cbr'), PosixPath('../data/Hulk/Incredible Hulk 600-611 (2009-2010)/Issues/Incredible Hulk 605 (2010).cbr'), PosixPath('../data/Hulk/Incredible Hulk 600-611 (2009-2010)/Issues/Incredible Hulk 608 (2010).cbr'), PosixPath('../data/Infinity Gauntlet/TPB/Infinity Gauntlet (TPB) (1992) GetComics.INFO.cbr'), PosixPath('../data/Infinity Gauntlet/Infinity Gauntlet Aftermath/TPB/Infinity Gauntlet Aftermath (2013) (Digital) (Kileko-Empire).cbr'), PosixPath('../data/Infinity Gauntlet/Issues/Infinity Gauntlet 005 (1992) (Digital) (Zone-Empire).cbr'), PosixPath('../data/Infinity Gauntlet/Issues/Infinity Gauntlet 003 (1991) (Digital) (Zone-Empire).cbr'), PosixPath('../data/Infinity Gauntlet/Issues/Infinity Gauntlet 002 (1991) (Digital) (Zone-Empire).cbr'), PosixPath('../data/Infinity Gauntlet/Issues/Infinity Gauntlet 004 (1991) (Digital) (Zone-Empire).cbr'), PosixPath('../data/Infinity Gauntlet/Issues/Infinity Gauntlet 001 (1991) (Digital) (Zone-Empire).cbr'), PosixPath('../data/Infinity Gauntlet/Issues/Infinity Gauntlet 006 (1992) (Digital) (Zone-Empire).cbr'), PosixPath('../data/Age of Ultron/Issues/Age of Ultron 009 (2013) (Digital) (Zone-Empire).cbr'), PosixPath('../data/Age of Ultron/Issues/Age of Ultron 004 (2013) (Digital) (Zone-Empire).cbr'), PosixPath('../data/Age of Ultron/Issues/Age of Ultron 10 (of 10) (2013) (digital) (Minutemen-PhD).cbr'), PosixPath('../data/Age of Ultron/Issues/Age of Ultron 02 (of 10) (2013) (digital) (Zone-Empire).cbr'), PosixPath('../data/Age of Ultron/Issues/Age of Ultron 008 (2013) (Digital) (Zone-Empire).cbr'), PosixPath('../data/Age of Ultron/Issues/Age of Ultron 003 (2013) (Zone-Empire).cbr'), PosixPath('../data/Age of Ultron/Issues/Age of Ultron 005 (2013) (Digital) (Zone-Empire).cbr'), PosixPath('../data/Age of Ultron/Issues/Age of Ultron 006 (2013) (Digital) (Zone-Empire).cbr'), PosixPath('../data/Age of Ultron/Issues/Age of Ultron 001 (2013) (Digital) (Zone-Empire).cbr'), PosixPath('../data/Age of Ultron/Issues/Age of Ultron 10AI (2013) (Digital) (Zone-Empire).cbr'), PosixPath('../data/Age of Ultron/Issues/Age of Ultron 007 (2013) (Digital) (Zone-Empire).cbr'), PosixPath('../data/Marvel Graphic Novel  (01 - 05)/MGN - 02 - Elric The Dreaming City.cbr'), PosixPath('../data/Marvel Graphic Novel  (01 - 05)/MGN - 05 - X-Men - God Loves Man Kills.cbr'), PosixPath('../data/Marvel Graphic Novel  (01 - 05)/MGN - 03 - Dreadstar.cbr'), PosixPath('../data/Venom (Vol. 2)/Venom 030 (2013) (digital) (Minutemen-PhD).cbr'), PosixPath('../data/Venom (Vol. 2)/Venom 037 (2013) (digital) (Minutemen-PhD).cbr'), PosixPath('../data/Venom (Vol. 2)/Venom 040 (2013) (digital) (Minutemen-PhD).cbr'), PosixPath('../data/Venom (Vol. 2)/Venom 031 (2013) (digital) (Minutemen-PhD).cbr'), PosixPath('../data/Venom (Vol. 2)/Venom 036 (2013) (digital) (Minutemen-PhD).cbr'), PosixPath('../data/Venom (Vol. 2)/Venom 041 (2013) (digital) (Minutemen-PhD).cbr'), PosixPath('../data/Venom (Vol. 2)/Venom 034 (2013) (digital) (Minutemen-PhD).cbr'), PosixPath('../data/Venom (Vol. 2)/Venom 033 (2013) (digital) (Minutemen-PhD).cbr'), PosixPath('../data/Venom (Vol. 2)/Venom 035 (2013) (digital) (Minutemen-PhD).cbr'), PosixPath('../data/Venom (Vol. 2)/Venom 032 (2013) (digital) (Minutemen-PhD).cbr'), PosixPath('../data/Venom (Vol. 2)/Venom 042 (2013) (digital) (Minutemen-PhD).cbr'), PosixPath('../data/Venom (Vol. 2)/Venom 028 (2013) (digital) (Minutemen-PhD).cbr'), PosixPath('../data/Venom (Vol. 2)/Venom 038 (2013) (digital) (Minutemen-PhD).cbr'), PosixPath('../data/Venom (Vol. 2)/Venom 029 (2013) (digital) (Minutemen-PhD).cbr'), PosixPath('../data/Venom (Vol. 2)/Venom 039 (2013) (digital) (Minutemen-PhD).cbr'), PosixPath('../data/Inhumans/Inhumans (01-12) (1998-1999)/Inhumans 008 (1999).cbr')]\n"
     ]
    }
   ],
   "source": [
    "print(   Path('../data/').rglob('*.cbr')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/srihari/Fun/Comics/data/Age of Ultron/Issues')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.library_dict['Age of Ultron']['issues']['parser'].volume_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_style": "center",
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class ComicParser(): #Parser object to extract name, first year and issue number.\n",
    "    def __init__(self, path):\n",
    "        self.comic_name = None\n",
    "        self.comic_year = None\n",
    "        self.issue_number = None\n",
    "        self.comic_path = path\n",
    "        self.comic_metadata = {}\n",
    "        self.comic_initiated = False\n",
    "\n",
    "    def parseComic(self):\n",
    "        self.comic_name = os.path.splitext(os.path.basename(self.comic_path))[0]\n",
    "        years = re.findall(r'\\(([12]\\d{3})', self.comic_name)\n",
    "        if years:\n",
    "            year_within_brackets = years[0]\n",
    "            if (len(year_within_brackets) == 4): #Stupid way of doing but good for now.\n",
    "                self.comic_year = int(year_within_brackets)\n",
    "            else:\n",
    "                self.comic_year = 0\n",
    "        self.issue_number = re.findall(r\"(\\d+\\.?\\d?[a-zA-Z]{0,3}?)(?:\\s*\\(of|\\s*\\([12]\\d{3}\\))\", self.comic_path) #Get the digits or digits with point number (19.1) or digits followed by letters (19.INH) either before \"(of\" or before a year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_style": "center",
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class VolumeParser:\n",
    "    def __init__(self, name, path):\n",
    "        self.volume_name = name\n",
    "        self.volume_path = path\n",
    "        self.volume_initiated = False\n",
    "        self.volumeDict = {'comics_in_folder' : {} } \n",
    "        self.volumeFetch = True\n",
    "        self.volumeTable = None\n",
    "        self.searchReturned = None\n",
    "        self.HEADERS = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:7.0) '\n",
    "                     'Gecko/20130825 Firefox/36.0'}\n",
    "        self.params = {'api_key':api_key, 'format': 'json'} \n",
    "                \n",
    "    def parseVolume(self): #Adds path and volume name to the parser object. Also parses comic. \n",
    "        comic_dir = self.volume_path\n",
    "        if '(' in self.volume_name:\n",
    "            #elf.volume_name = os.path.basename(self.volume_path).split(' (')[0] \n",
    "            self.volume_name = self.volume_name.split(' (')[0] \n",
    "        else:    \n",
    "            #self.volume_name = os.path.basename(self.volume_path) \n",
    "            self.volume_name = self.volume_name\n",
    "        \n",
    "        print(self.volume_name)\n",
    "#         self.volumeDict['from_file_volume_name'] = self.volume_name        \n",
    "#         for entry in os.listdir(comic_dir):\n",
    "#             if not entry.startswith(\".\") and check_comic(entry):\n",
    "#                 comic = ComicParser(os.path.join(comic_dir,entry)) #convert to path join volume path and entry\n",
    "#                 comic.parseComic()            \n",
    "#                 self.volumeDict['comics_in_folder'].update({comic.comic_name : comic})\n",
    "                                \n",
    "#         print(str(len(self.volumeDict['comics_in_folder']))+' comics added in volume ' + self.volume_name +'.')    \n",
    "        \n",
    "    def searchQuery(self,api_key):\n",
    "        \"\"\"\n",
    "        Search Comic Vine Servers\n",
    "        \"\"\"\n",
    "        print(\"Fetching from Comic Vine servers\")\n",
    "        years = [self.volumeDict['comics_in_folder'][key].comic_year for key in self.volumeDict['comics_in_folder'].keys() if self.volumeDict['comics_in_folder'][key].comic_year]        \n",
    "        searchtext = self.volumeDict['from_file_volume_name']\n",
    "        if years:\n",
    "            searchtext += (' '+str(years[0]))\n",
    "        print('Querying for '+searchtext)\n",
    "        firstresponse = cv.search(searchtext, resources=['volume']) #Search for volume name with year\n",
    "        self.searchReturned = firstresponse.results\n",
    "        \n",
    "    def findBestSearch(self):\n",
    "        \"\"\"\n",
    "\n",
    "        Finding best search among Volumes. 2 main information considered \n",
    "        here are number of files in folder folder (which is assumed to be \n",
    "        total number of issues in that volume) and year range obtained \n",
    "        from comic file names.        \n",
    "        \n",
    "        \"\"\"\n",
    "        print(\"Finding best match\")\n",
    "        expected_num_comics = len(self.volumeDict['comics_in_folder'])    \n",
    "        existing_comics = list(self.volumeDict['comics_in_folder'].keys())\n",
    "        years = [self.volumeDict['comics_in_folder'][key].comic_year for key in self.volumeDict['comics_in_folder'].keys() if self.volumeDict['comics_in_folder'][key].comic_year]\n",
    "        \n",
    "        \n",
    "        flag=False\n",
    "        best_index = 0\n",
    "        for indx, each_result in enumerate(self.searchReturned):    \n",
    "            if indx is 0:\n",
    "                each_result['match_score'] = 30.0 #First result returned is the best result.\n",
    "            elif indx is not 0:\n",
    "                each_result['match_score'] = 0.0\n",
    "            if expected_num_comics == each_result['count_of_issues']:\n",
    "                each_result['match_score'] += 10.0 \n",
    "            if years:    \n",
    "                if (min(years)<=int(each_result['start_year'])<=max(years)):\n",
    "                    each_result['match_score'] +=40.0\n",
    "                    \n",
    "                    \n",
    "            ######If scores are still really terrible, then do individual issues check for all issues in search returns.         \n",
    "            if flag and each_result['match_score']<=40:\n",
    "                detailresponse = requests.get(each_result['api_detail_url'], headers=self.HEADERS, params=self.params)\n",
    "                #print(detailresponse.json())\n",
    "                titles_in_vol = [each['name'] for each in detailresponse.json()['results']['issues']]\n",
    "                each_result['match_score'] +=fuzz.token_set_ratio(titles_in_vol, exist)\n",
    "            \n",
    "            \n",
    "            \n",
    "                    \n",
    "            if each_result['match_score']>=np.array(self.searchReturned)[best_index]['match_score']: #Also assumed that search results are coming back sorted in relavance.\n",
    "                best_index = indx\n",
    "        self.volumeDict['best_search']=np.array(self.searchReturned)[best_index]\n",
    "        print('Match Score : '+ str(self.volumeDict['best_search']['match_score']))        \n",
    "    \n",
    "    def confirmResult(self):\n",
    "        print_com_meta(self.volumeDict['best_search'], 'Best Result:')\n",
    "        confirmation = query_yes_no(\"Is the information correct?\")\n",
    "        choice = None\n",
    "        while True:\n",
    "            clear_output()\n",
    "            if not confirmation: \n",
    "                for idx, each in enumerate(self.searchReturned):\n",
    "                    print_com_meta(each, idx+1)\n",
    "                choice = sanitised_input(\"Please make a manual choice between 1-10 : \", int, 1,10)\n",
    "                print_com_meta(self.searchReturned[choice-1], 'Your Choice : ')\n",
    "                confirmation = query_yes_no(\"Is the information correct?\")\n",
    "            else:\n",
    "                if choice:\n",
    "                    self.volumeDict['best_search'] = self.searchReturned[choice-1]\n",
    "                break\n",
    "    \n",
    "    def fetchVolumeMetadata(self):                                        \n",
    "        detailresponse = requests.get(self.volumeDict['best_search']['api_detail_url'], headers=self.HEADERS, params=self.params)\n",
    "        fetched_volume = detailresponse.json()\n",
    "        self.volumeDict['detailed_meta'] = fetched_volume['results']        \n",
    "        #Image Directory\n",
    "        orig_directory = './Resources/Images/VolumeArt/'\n",
    "        img_name = os.path.basename(self.volumeDict['detailed_meta']['image']['original_url'])\n",
    "        img_path = os.path.join(orig_directory,img_name)\n",
    "        #Fetch Image\n",
    "        urlretrieve(self.volumeDict['detailed_meta']['image']['original_url'], img_path)        \n",
    "        self.volume_initiated = True\n",
    "        volume = Volume(\n",
    "                        id = self.volumeDict['detailed_meta']['id'],\n",
    "                        name = self.volumeDict['detailed_meta']['name'],\n",
    "                        aliases = self.volumeDict['detailed_meta']['aliases'],\n",
    "                        count_of_issues = self.volumeDict['detailed_meta']['count_of_issues'],\n",
    "                        date_added = self.volumeDict['detailed_meta']['date_added'],\n",
    "                        date_last_updated = self.volumeDict['detailed_meta']['date_last_updated'],\n",
    "                        deck = self.volumeDict['detailed_meta']['deck'],\n",
    "                        description = re.sub(r'<[^>]*>', '', self.volumeDict['detailed_meta']['description']), #remove all within angle brackets\n",
    "                        publisher = self.volumeDict['detailed_meta']['publisher']['name'], #Later to be changed to publisher object\n",
    "                        start_year = self.volumeDict['detailed_meta']['start_year'],\n",
    "                        comicvine_api_detail_url = self.volumeDict['detailed_meta']['api_detail_url'],\n",
    "                        comicvine_image = self.volumeDict['detailed_meta']['image']['original_url'], #image\n",
    "                        comicvine_site_detail_url = self.volumeDict['detailed_meta']['site_detail_url'],\n",
    "                        local_path = self.volume_path,\n",
    "                        local_image_path = img_path,\n",
    "                        #character_credits = Column(String)\n",
    "                        #concept_credits = Column(String)\n",
    "                        #team_credits = Column(String)\n",
    "                        #location_credits = Column(String)\n",
    "                        #object_credits = Column(String)\n",
    "                        #person_credits = Column(String)\n",
    "                        )\n",
    "        self.volumeTable = volume        \n",
    "        \n",
    "    def fetchComicsMetadata(self, api_key):\n",
    "        comic_fetch_loop = tqdm(self.volumeDict['detailed_meta']['issues'])\n",
    "        comicObjects = []\n",
    "        issue_directory = './Resources/Images/IssueArt/'                        \n",
    "        for each_issue in comic_fetch_loop:\n",
    "            per_issue_response = requests.get(each_issue['api_detail_url'], headers=self.HEADERS, params=self.params).json()['results']\n",
    "            img_name = os.path.basename(per_issue_response['image']['original_url'])\n",
    "            img_path = os.path.join(issue_directory,img_name)\n",
    "            #Fetch Image if doesnt exist\n",
    "            if not os.path.isfile(img_path):\n",
    "                urlretrieve(per_issue_response['image']['original_url'], img_path) \n",
    "            \n",
    "            comic = Comic(id = per_issue_response['id'],\n",
    "                          name = per_issue_response['name'],\n",
    "                          aliases = per_issue_response['aliases'],\n",
    "                          deck = per_issue_response['deck'],\n",
    "                          description = re.sub(r'<[^>]*>', '', per_issue_response['description']),\n",
    "                          cover_date = per_issue_response['cover_date'],\n",
    "                          date_added = per_issue_response['date_added'],\n",
    "                          date_last_updated = per_issue_response['date_last_updated'],\n",
    "                          issue_number = per_issue_response['issue_number'],\n",
    "                          comicvine_api_detail_url = per_issue_response['api_detail_url'],\n",
    "                          comicvine_image = per_issue_response['image']['original_url'],\n",
    "                          local_image_path = img_path\n",
    "            )\n",
    "            comicObjects.append(comic)\n",
    "            comic_fetch_loop.set_postfix(Status='Added '+str(comic.name))            \n",
    "        self.volumeTable.comics=set(comicObjects)\n",
    "     \n",
    "    def commit_to_db(self, dbpath='sqlite:///comicdb.db'):\n",
    "        \n",
    "        app = Flask(__name__)\n",
    "        app.config['SQLALCHEMY_DATABASE_URI'] = dbpath\n",
    "        db = SQLAlchemy(app)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        engine = create_engine(dbpath, echo=False)\n",
    "        Base.metadata.create_all(engine)\n",
    "        Session = sessionmaker(bind=engine)\n",
    "        session = Session()\n",
    "        session.add(self.volumeTable)\n",
    "        \n",
    "        try:\n",
    "            session.commit()\n",
    "        except IntegrityError:\n",
    "            session.rollback()\n",
    "        \n",
    "        #session.commit()\n",
    "        session.close()\n",
    "        engine.dispose()\n",
    "\n",
    "            \n",
    "#             for key in self.volumeDict['comics_in_folder'].keys():\n",
    "#                 if self.volumeDict['comics_in_folder'][key].issue_number == per_issue_response['issue_number'] and self.volumeDict['comics_in_folder'][key].comic_initiated == False:\n",
    "#                     self.volumeDict['comics_in_folder'][key].comic_metadata = per_issue_response\n",
    "#                     self.volumeDict['comics_in_folder'][key].comic_initiated = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.VolumeParser at 0x11efcc0f0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.library_dict['Infinity Gauntlet']['tpb']['volume_parser']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1 = VolumeParser('./data/Infinity Gauntlet')\n",
    "vol1.parseVolume()\n",
    "vol1.searchQuery(api_key)\n",
    "vol1.findBestSearch()\n",
    "vol1.confirmResult()\n",
    "#vol1.fetchVolumeMetadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1.volumeDict['best_search']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1.fetchVolumeMetadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1.fetchComicsMetadata(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1.commit_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = {subdir:files for subdir, dirs, files in os.walk('./data') for name in files if name.endswith(('cbr', 'cbz'))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(subs.keys())\n",
    "#subs['./data/Thor/Thor Vol. 2 (1998-2004)/Issues']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1.volumeDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainp = Path('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = list({each.parent for each_ext in ['*.cbr', '*.cbz'] for each in mainp.rglob(each_ext)})\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(folders[0].glob('*'))[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_search = []\n",
    "for each in folders:\n",
    "    if 'Issue' in each.name or 'TPB' in each.name:\n",
    "        to_search.append(each.parent.name)\n",
    "    else:\n",
    "        to_search.append(each.name)\n",
    "to_search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
